2022-08-15 10:44:46.339401: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home/sofia/miniconda/envs/deeplabcut-res/lib/python3.8/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import Int64Index as NumericIndex
/home/sofia/DeepLabCut/deeplabcut/__init__.py:81: UserWarning: 
        As PyTorch is not installed, unsupervised identity learning will not be available.
        Please run `pip install torch`, or ignore this warning.
        
  warnings.warn(
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21]],
 'all_joints_names': ['Nose',
                      'Eye',
                      'Nearknee',
                      'Nearfrontfetlock',
                      'Nearfrontfoot',
                      'Offknee',
                      'Offfrontfetlock',
                      'Offfrontfoot',
                      'Shoulder',
                      'Midshoulder',
                      'Elbow',
                      'Girth',
                      'Wither',
                      'Nearhindhock',
                      'Nearhindfetlock',
                      'Nearhindfoot',
                      'Hip',
                      'Stifle',
                      'Offhindhock',
                      'Offhindfetlock',
                      'Offhindfoot',
                      'Ischium'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 8,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HorsesMay8/Horses_Byron53shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': '/home/sofia/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HorsesMay8/Documentation_data-Horses_53shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.0001, 7500], ['5e-05', 12000], ['1e-05', 200000]],
 'net_type': 'resnet_50',
 'num_joints': 22,
 'optimizer': 'adam',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': '/home/sofia/datasets/Horse10_AL_unif/Horse10_AL_unif000',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': '/home/sofia/datasets/Horse10_AL_unif/Horse10_AL_unif000/dlc-models/iteration-0/HorsesMay8-trainset53shuffle1/train/snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2022-08-15 10:44:51.611837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-08-15 10:44:52.105106: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-08-15 10:44:52.105193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20545 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:1a:00.0, compute capability: 8.6
2022-08-15 10:44:52.519361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20545 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:1a:00.0, compute capability: 8.6
2022-08-15 10:44:53.753228: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-08-15 10:45:01.503632: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401
/home/sofia/miniconda/envs/deeplabcut-res/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
iteration: 1000 loss: 0.0387 lr: 0.0001
iteration: 2000 loss: 0.0223 lr: 0.0001
iteration: 3000 loss: 0.0186 lr: 0.0001
iteration: 4000 loss: 0.0158 lr: 0.0001
iteration: 5000 loss: 0.0143 lr: 0.0001
iteration: 6000 loss: 0.0130 lr: 0.0001
iteration: 7000 loss: 0.0121 lr: 0.0001
iteration: 8000 loss: 0.0110 lr: 5e-05
iteration: 9000 loss: 0.0099 lr: 5e-05
iteration: 10000 loss: 0.0097 lr: 5e-05
iteration: 11000 loss: 0.0094 lr: 5e-05
iteration: 12000 loss: 0.0092 lr: 5e-05
iteration: 13000 loss: 0.0083 lr: 1e-05
iteration: 14000 loss: 0.0082 lr: 1e-05
iteration: 15000 loss: 0.0081 lr: 1e-05
iteration: 16000 loss: 0.0079 lr: 1e-05
iteration: 17000 loss: 0.0080 lr: 1e-05
iteration: 18000 loss: 0.0078 lr: 1e-05
iteration: 19000 loss: 0.0078 lr: 1e-05
iteration: 20000 loss: 0.0078 lr: 1e-05
iteration: 21000 loss: 0.0077 lr: 1e-05
iteration: 22000 loss: 0.0077 lr: 1e-05
iteration: 23000 loss: 0.0076 lr: 1e-05
iteration: 24000 loss: 0.0076 lr: 1e-05
iteration: 25000 loss: 0.0077 lr: 1e-05
iteration: 26000 loss: 0.0075 lr: 1e-05
iteration: 27000 loss: 0.0075 lr: 1e-05
iteration: 28000 loss: 0.0074 lr: 1e-05
iteration: 29000 loss: 0.0074 lr: 1e-05
iteration: 30000 loss: 0.0074 lr: 1e-05
iteration: 31000 loss: 0.0075 lr: 1e-05
iteration: 32000 loss: 0.0073 lr: 1e-05
iteration: 33000 loss: 0.0073 lr: 1e-05
iteration: 34000 loss: 0.0074 lr: 1e-05
iteration: 35000 loss: 0.0073 lr: 1e-05
iteration: 36000 loss: 0.0073 lr: 1e-05
iteration: 37000 loss: 0.0071 lr: 1e-05
iteration: 38000 loss: 0.0072 lr: 1e-05
iteration: 39000 loss: 0.0071 lr: 1e-05
iteration: 40000 loss: 0.0069 lr: 1e-05
iteration: 41000 loss: 0.0069 lr: 1e-05
iteration: 42000 loss: 0.0068 lr: 1e-05
iteration: 43000 loss: 0.0068 lr: 1e-05
iteration: 44000 loss: 0.0066 lr: 1e-05
iteration: 45000 loss: 0.0066 lr: 1e-05
iteration: 46000 loss: 0.0065 lr: 1e-05
iteration: 47000 loss: 0.0066 lr: 1e-05
iteration: 48000 loss: 0.0065 lr: 1e-05
iteration: 49000 loss: 0.0065 lr: 1e-05
iteration: 50000 loss: 0.0064 lr: 1e-05
iteration: 51000 loss: 0.0064 lr: 1e-05
iteration: 52000 loss: 0.0064 lr: 1e-05
iteration: 53000 loss: 0.0062 lr: 1e-05
iteration: 54000 loss: 0.0063 lr: 1e-05
iteration: 55000 loss: 0.0062 lr: 1e-05
iteration: 56000 loss: 0.0061 lr: 1e-05
iteration: 57000 loss: 0.0061 lr: 1e-05
iteration: 58000 loss: 0.0062 lr: 1e-05
iteration: 59000 loss: 0.0060 lr: 1e-05
iteration: 60000 loss: 0.0061 lr: 1e-05
iteration: 61000 loss: 0.0060 lr: 1e-05
iteration: 62000 loss: 0.0060 lr: 1e-05
iteration: 63000 loss: 0.0061 lr: 1e-05
iteration: 64000 loss: 0.0059 lr: 1e-05
iteration: 65000 loss: 0.0060 lr: 1e-05
iteration: 66000 loss: 0.0060 lr: 1e-05
iteration: 67000 loss: 0.0060 lr: 1e-05
iteration: 68000 loss: 0.0058 lr: 1e-05
iteration: 69000 loss: 0.0060 lr: 1e-05
iteration: 70000 loss: 0.0059 lr: 1e-05
iteration: 71000 loss: 0.0059 lr: 1e-05
iteration: 72000 loss: 0.0058 lr: 1e-05
iteration: 73000 loss: 0.0059 lr: 1e-05
iteration: 74000 loss: 0.0058 lr: 1e-05
iteration: 75000 loss: 0.0058 lr: 1e-05
iteration: 76000 loss: 0.0058 lr: 1e-05
iteration: 77000 loss: 0.0058 lr: 1e-05
iteration: 78000 loss: 0.0057 lr: 1e-05
iteration: 79000 loss: 0.0057 lr: 1e-05
iteration: 80000 loss: 0.0058 lr: 1e-05
iteration: 81000 loss: 0.0057 lr: 1e-05
iteration: 82000 loss: 0.0056 lr: 1e-05
iteration: 83000 loss: 0.0056 lr: 1e-05
iteration: 84000 loss: 0.0057 lr: 1e-05
iteration: 85000 loss: 0.0056 lr: 1e-05
iteration: 86000 loss: 0.0056 lr: 1e-05
iteration: 87000 loss: 0.0057 lr: 1e-05
iteration: 88000 loss: 0.0056 lr: 1e-05
iteration: 89000 loss: 0.0056 lr: 1e-05
iteration: 90000 loss: 0.0056 lr: 1e-05
iteration: 91000 loss: 0.0055 lr: 1e-05
iteration: 92000 loss: 0.0055 lr: 1e-05
iteration: 93000 loss: 0.0056 lr: 1e-05
iteration: 94000 loss: 0.0056 lr: 1e-05
iteration: 95000 loss: 0.0055 lr: 1e-05
iteration: 96000 loss: 0.0054 lr: 1e-05
iteration: 97000 loss: 0.0056 lr: 1e-05
iteration: 98000 loss: 0.0055 lr: 1e-05
iteration: 99000 loss: 0.0055 lr: 1e-05
iteration: 100000 loss: 0.0055 lr: 1e-05
iteration: 101000 loss: 0.0055 lr: 1e-05
